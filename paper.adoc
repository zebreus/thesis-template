:doctype: book
:imagesdir: images
:stylesheet: paper.css
// Disable generating an update label at the bottom of the doc.
:last-update-label!:
// Setup highlight.js to use a local version with a local stylesheet
:source-highlighter: highlight.js
:highlightjs-theme: thesis
:highlightjsdir: libraries/highlightjs
// Enable rendering mathequations
:stem:
// Generate table of contents at the toc macro
// Also disableing section numbers for now, as we only start numbering after the toc. See the macros there
:toc: macro
:toclevels: 3
:sectanchors:
// Disable title page
// We will build the title page manually for maximum flexibility
:notitle:
:title-page: false
// Refer to things like "Figure 1" instead of by their name
:xrefstyle: short
// Prefetch and inline diagrams with kroki but not in vscode
ifndef::env-vscode[]
:kroki-fetch-diagram: true
:kroki-default-options: inline
endif::env-vscode[]

image::logo_hda.svg[role=logo]

[.university.text-center]
Darmstadt University of Applied Sciences

[.faculty.text-center]
Faculty of Computer Science

[discrete#main-title]
= Is high-level synthesis from Rust possible using existing tools?

[.description.text-center]
Submitted in partial fulfillment of the requirements for the degree of +
Bachelor of Science (B.Sc.)

[.presented-by.text-center]
by +
*Zebreus* +
[small]+Matriculation number: XXXXXX+ +


[.other-people]
First Examiner:: Prof. Dr. Some Person
Second Examiner:: Prof. Dr. Another Person

<<<



<<<

[discrete]
== Declaration

If you are writing a thesis you probably need this bit to confirm that you wrote it all by yourself. This template adds the `signature-required` CSS class which add a nice line where you can write your name.

If you are not writing a thesis, just delete this whole section.

_Darmstadt, 5.7.2023_

[.signature-required]
Zebreus

<<<

[discrete]
== Abstract
// A summary of the contents in English of about one page. The following
// points should be addressed in particular:

// * Motivation: Why did this work come about? Why is the topic of the
// work interesting (for the general public)? The motivation should be
// abstracted as far as possible from the specific tasks that may be given
// by a company.
// * Content: What is the content of this thesis? What exactly is covered in
// the thesis? The methodology and working method should be briefly
// discussed here.
// * Results: What are the results of this work? A brief overview of the
// Most actual results as a teaser to read the complete thesis.


// Generated with chatgpt
This document presents the Asciidoctor.js thesis template, which offers a versatile and easily understandable alternative to traditional typesetting systems for scientific writing. The template leverages the flexibility of web technologies, allowing seamless design modifications and rendering both PDF and website versions of the thesis. The source document structure resembles markdown, enhancing its readability. This abstract provides an overview of the template's benefits, getting started instructions, toolchain details, customization options using JavaScript, integration of source code listings and syntax highlighting, philosophical considerations behind the design decisions, and a comprehensive guide to using the template's features for scientific writing. Overall, the Asciidoctor.js thesis template provides a user-friendly and efficient approach for creating scientific theses, offering enhanced readability and ease of customization compared to traditional typesetting systems.

// The table of contents gets inserted here.
toc::[]

// This generates the tables for listings, figures, and tables
// If you do not need all of them, just modiy that file.

<<<

// Start with section and part numbering
:sectnums:
:part-signifier: Part
:listing-caption: Listing
:partnums:

// Main part starts here
[.reset-pages]
= Thesis

== Introduction

The popularity of the Rust programming language is rising, and it is one of the most admired programming languages <<Sta16>> <<Sta20>> <<Sta23>> <<Bug22>>. It integrates modern tooling like standardized dependency management, testing, documentation generation, formatting, and building. In the future, adoption will probably increase further, and it could replace {cpp} as the most common systems programming language <<Bug22>>.
Rust also provides benefits in domains other than systems programming. It has been shown that Rust can be used for other fields such as GPU programming, web development, or logic programming <<Sah22>> <<Byc22>> <<Kyr22>>. These fields profit from some of the benefits of Rust, like guaranteed memory safety and improved productivity  <<Bug22>> <<Cos19>>.

This paper explores how Rust can be used in FPGA firmware development. Usually, FPGA firmware is developed in a hardware description language (HDL) such as Verilog or VHDL. In these languages, the programmer has to describe the hardware in detail. This low-level approach can lead to efficient designs but is quite time-consuming <<Mil20>>. The RustHDL project facilitates expressing hardware descriptions in Rust similar to traditional HDLs <<Smi21>>. In addition to manually designing hardware in an HDL, it is also possible to use high-level synthesis (HLS) to generate hardware descriptions in HDLs from an algorithmic description written in high-level programming languages. Typically systems programming languages are used for writing these specifications. This increases productivity at the cost of slightly less optimized designs <<Mil20>>. There are multiple HLS tools available that can synthesize HDL descriptions from {cpp} code. Some of these tools are based on the LLVM compiler infrastructure <<Nan16>>. The only previous report on using Rust as an HLS language focuses on a limited subset of Rust and its formal verification <<Har22>>. 

// As Rust is also based on LLVM, it can be used with these tools too. 

// To determine the feasibility of utilizing Rust as a source language for High-Level Synthesis (HLS).
An investigation to identify HLS tools compatible with Rust was conducted. A modular approach was developed to seamlessly integrate HLS tools with RustHDL. By employing this approach, a proof-of-concept integration with the PandA Bambu HLS framework was achieved, demonstrating the feasibility of using Rust as a source language for HLS. The performance of designs generated from various algorithms was compared with that of designs generated from algorithmically equivalent {cpp} code. The evaluation showed that, in most cases, the Rust-based workflow produced designs with similar characteristics to those derived from {cpp}-based workflows.

// CAUTION: Rework the start of this section

== Using figures

All chart types except for vega-lite should just be used as asciidoctor-kroki charts. You can reference your chart in the text lik <<sample-nomnoml-chart>>, by giving it an id, in this case `sample-nomnoml-chart`.

.Sample nomnoml chart
[nomnoml,id=sample-nomnoml-chart]
....
[<actor>Jolly;Sailor]
[Jolly;Sailor]->[Pirate]
[Jolly;Sailor]->[rum]

[Pirate|
  [beard]--[parrot]
  [beard]-:>[foul mouth]
]
[Pirate]-> *[rum|tastiness: int|swig()]
[<abstract>Marauder]<:--[Pirate]

[<table>mischief| bawl | sing || yell | drink ]
[Pirate] - 0..7[mischief]

#gutter: 10
#lineWidth: 1.25
#stroke: #000000
#font: Spectral
#fill: #f7f8f7; #ffffff; #f7f8f7; #ffffff; #f7f8f7; #ffffff
....

.Source for the section above
[source,asciidoc]
----
All chart types except for vega-lite should just be used as asciidoctor-kroki charts. You can reference your chart in the text lik <<sample-nomnoml-chart>>, by giving it an id, in this case `sample-nomnoml-chart`.

.Sample nomnoml chart
[nomnoml,id=sample-nomnoml-chart]
....
[<actor>Jolly;Sailor]
[Jolly;Sailor]->[Pirate]
[Jolly;Sailor]->[rum]

[Pirate|
  [beard]--[parrot]
  [beard]-:>[foul mouth]
]
[Pirate]-> *[rum|tastiness: int|swig()]
[<abstract>Marauder]<:--[Pirate]

[<table>mischief| bawl | sing || yell | drink ]
[Pirate] - 0..7[mischief]

#gutter: 10
#lineWidth: 1.25
#stroke: #000000
#font: Spectral
#fill: #f7f8f7; #ffffff; #f7f8f7; #ffffff; #f7f8f7; #ffffff
....
----

.Sample wavedrom chart
[wavedrom,id=sample-wavedrom-chart]
....
include::assets/keccak_clang_speed.wavejson.json[]
....

.Source for the wavedrom chart
[source,asciidoc]
----
.Sample wavedrom chart
[wavedrom,id=sample-wavedrom-chart]
....
\include::assets/keccak_clang_speed.wavejson.json[]
....
----

To make the chart extend over the margins of the page, add a `slightly-oversized`, `oversized` or `completly-oversized` to the chart.

.Source for the section above
.Sample graphviz graph
[graphviz.slightly-oversized,id=minmax-speed-cfg,width=570px]
....
include::assets/minmax_speed_control_flow.dot[]
....

[source,asciidoc]
----
.Sample graphviz graph
[graphviz.slightly-oversized,id=minmax-speed-cfg,width=570px]
....
\include::assets/minmax_speed_control_flow.dot[]
....
----

=== vega-lite

Vega-lite is the preferred way to display any data-driven charts. You use the included `vega-chart.adoc` script to include vega-lite charts. It detects if the document is currently built for a browser or as a PDF. If the document is built for a browser, it will include the chart directly via the vega javascript library. That way the chart supports tooltips and other interactive features.

[source.completly-oversized,asciidoc,subs=attributes]
----
.Sample vega-lite chart
:chart-id: id=minmax-area
:vega-lite-filename: processed-assets/minmax_overview_area.vl.json
\include::scripts/vega-chart.adoc[]
----

.Sample vega-lite chart
:chart-id: id=minmax-area
:vega-lite-filename: processed-assets/minmax_overview_area.vl.json
include::scripts/vega-chart.adoc[]

== Using source listings

Asciidoc also supports source listings. A short verilog listing is shown in <<short-verilog-listing>>.

.Short Verilog listing
[source#short-verilog-listing,verilog]
----
module Blinker (input clock, output blinker);
  reg [6:0] counter = 0;
  reg state = 0;
  always @(posedge clock) begin
    counter <= counter + 1;
    if (counter == 9) begin
      state   <= ~state;
      counter <= 0;
    end
  end
  assign blinker = state;
endmodule
----

<<long-rust-listing>> shows a long Rust listing. This template has a `.linenums` class that can be added to code listings to enable line numbers. The normal asciidoc `linenums` attribute is not supported.

.Long rust listing with line numbers
[source#long-rust-listing.linenums,rust]
----
include::assets/long_rust_listing.rs[tag=function]
----

Your code should be not wider than 80 characters. If it is try using the `oversized` classes to avoid unnecessary line breaks.


== Future work


// How can the Rust compiler be made to generate better LLVM IR for HLS?

// Measure more test cases

// Test out the limitations of the toolchain

// 



// Can it be better than CPP when the tools are adjusted for Rust LLVM?
Future work on HLS from Rust should focus on improving support for Rust-generated LLVM IR in HLS tools. While Bambu can currently synthesize the LLVM IR generated by Rust, it seems possible to improve the generated designs in some cases. Finding these cases and improving Bambu to handle them should be possible.

It would also be interesting to see if the LLVM IR generated by Rust can be improved to generate better designs. Our toolchain builds every project dependency separately and then links them together. This is not ideal, as it does not allow the compiler to perform cross-crate link-time optimizations. This would probably require adjusting cargo or the Rust compiler to allow link-time optimizations when compiling to LLVM IR. The toolchain only configures the Rust compiler with the settings necessary for generating LLVM IR that Bambu can synthesize. Besides that, it uses rustc's default optimization profiles for speed and size. There are probably significant improvements possible by evaluating which optimizations are useful for HLS and which are not.


[glossary]
== List of abbreviations
// Abbreviations from here will automatically be linked to the document

// Abbreviations in random order and links to read more about them
[glossary]
[[FPGA]]FPGA:: Field-Programmable Gate Array link:pass:[https://en.wikipedia.org/wiki/Field-programmable_gate_array][üîó^]
[[HLS]]HLS:: High-Level Synthesis link:pass:[https://en.wikipedia.org/wiki/High-level_synthesis][üîó^]
[[HDL]]HDL:: Hardware Description Language link:pass:[https://en.wikipedia.org/wiki/Hardware_description_language][üîó^]
[[SRAM]]SRAM:: Static RAM link:pass:[https://en.wikipedia.org/wiki/Static_random-access_memory][üîó^]
[[ADL]]ADL:: Accelerator Design Language link:pass:[https://www.sigarch.org/hdl-to-adl/][üîó^]
[[GPU]]GPU:: Graphics Processing Unit link:pass:[https://en.wikipedia.org/wiki/Graphics_processing_unit][üîó^]
[[LLVM_IR]]LLVM IR:: LLVM Intermediate Representation link:pass:[https://en.wikipedia.org/wiki/LLVM#Intermediate_representation][üîó^]
[[RTL]]RTL:: Register-Transfer Level link:pass:[https://en.wikipedia.org/wiki/Register-transfer_level][üîó^]
[[DUT]]DUT:: Design/Device Under Test link:pass:[https://en.wikipedia.org/wiki/Test_bench][üîó^]
[[ASIC]]ASIC:: Application Specific Integrated Circuit link:pass:[https://en.wikipedia.org/wiki/Application-specific_integrated_circuit][üîó^]
[[QoR]]QoR:: Quality of Results link:pass:[https://en.wikipedia.org/wiki/Quality_of_results][üîó^]
[[CPU]]CPU:: Central Processing Unit link:pass:[https://en.wikipedia.org/wiki/Central_processing_unit#Structure_and_implementation][üîó^]
[[LUT]]LUT:: Look-Up Table link:pass:[https://en.wikipedia.org/wiki/Lookup_table][üîó^]
[[FF]]FF:: Flip-Flop link:pass:[https://en.wikipedia.org/wiki/Flip-flop_(electronics)][üîó^]
[[DFF]]DFF:: D Flip-Flop link:pass:[https://en.wikipedia.org/wiki/Flip-flop_(electronics)#D_flip-flop][üîó^]
[[BRAM]]BRAM:: Block RAM link:pass:[https://nandland.com/lesson-15-what-is-a-block-ram-bram/][üîó^]
[[DSP]]DSP:: Digital Signal Processor link:pass:[https://www.fpgakey.com/tutorial/section613][üîó^]
[[CLB]]CLB:: Configurable Logic Block link:pass:[https://www.fpgakey.com/wiki/details/51][üîó^]
[[LB]]LB:: Logic Block link:pass:[https://www.fpgakey.com/wiki/details/51][üîó^]
[[LE]]LE:: Logic Element link:pass:[https://www.fpgakey.com/wiki/details/342][üîó^]
[[RAII]]RAII:: Resource Acquisition Is Initialization / Scope-Bound Resource Management link:pass:[https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization][üîó^]
[[HIR]]HIR:: High-level Intermediate Representation link:pass:[https://rustc-dev-guide.rust-lang.org/hir.html][üîó^]
[[THIR]]THIR:: Typed HIR link:pass:[https://rustc-dev-guide.rust-lang.org/thir.html][üîó^]
[[MIR]]MIR:: Mid-level Intermediate Representation link:pass:[https://rustc-dev-guide.rust-lang.org/mir/index.html][üîó^]
[[PAL]]PAL:: Programmable Array Logic link:pass:[https://en.wikipedia.org/wiki/Programmable_Array_Logic][üîó^]
[[CFG]]CFG:: Control-Flow Graph link:pass:[https://en.wikipedia.org/wiki/Control-flow_graph][üîó^]
[[SSA]]SSA:: Static Single Assignment link:pass:[https://en.wikipedia.org/wiki/Static_single-assignment_form][üîó^]
[[GCC]]GCC:: GNU Compiler Collection link:pass:[https://gcc.gnu.org/][üîó^]
[[LLVM]]LLVM:: LLVM is not an acronym link:pass:[https://llvm.org/][üîó^]
[[VHDL]]VHDL:: Very High-Speed Integrated Circuit Hardware Description Language link:pass:[https://en.wikipedia.org/wiki/VHDL][üîó^]

[bibliography]
== References

// Citation style:
// Line 1: All authors full first and last names. Authors seperated by commas.
// Line 2: Title in italics.
// Line 3: Journal/Conference name or any other information about what gives the source credibility.
// Line 4: doi with attached hyperlink. For digital editions, also link the PDF with a üìÅ icon
// +Authors seperated by commas+

// Claims to have a transpiler from a subset of Rust (RAR) to restricted algorithmic C (RAC) that can be synthesized to FPGA. No source.
// The first paper to mention HLS from Rust. 
* [[[Har22]]]
+David Hardin+ +
_Hardware/Software Co-Assurance using the Rust Programming Language and ACL2_ +
arXiv preprint +
link:pass:[https://doi.org/10.48550/arXiv.2205.11709][10.48550/arXiv.2205.11709^]
link:pass:[https://arxiv.org/abs/2205.11709v1][üìÅ^]

// * [[[Rog20]]]
// Rogers, Samuel and Slycord, Joshua and Baharani, Mohammadreza and Tabkhi, Hamed,
// _gem5-SALAM: A System Architecture for LLVM-based Accelerator Modeling_,
// 2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), 471-482,
// 2020.
// link:pass:[https://ieeexplore.ieee.org/abstract/document/9251937][üîó^]

// * [[[Li21]]]
// Li, Rui and Berkley, Lincoln and Yang, Yihang and Manohar, Rajit,
// _Fluid: An Asynchronous High-level Synthesis Tool for Complex Program Structures_,
// 2021 27th IEEE International Symposium on Asynchronous Circuits and Systems (ASYNC), 1-8,
// 2020.
// link:pass:[https://ieeexplore.ieee.org/abstract/document/9565447][üîó^]

// * [[[Lia23]]]
// Liang, Geng-Ming and Yuan, Chuan-Yue and Yuan, Meng-Shiun and Chen, Tai-Liang and Chen, Kuan-Hsun and Lee, Jenq-Kuen,
// _The Support of MLIR HLS Adaptor for LLVM IR_,
// Workshop Proceedings of the 51st International Conference on Parallel Processing, 1-8,
// 2020.
// link:pass:[https://doi.org/10.1145/3547276.3548515][üîó^]

// Bambu provides a research environment to experiment with new ideas across HLS, high-level verification, and debugging.
// Bambu input: standard C/{cpp} specifications, LLVM IR, IRs from GCC
// Includes many optimizations
// Makes it easy to integrate new transformations and optimizations
// Is open-source
// Bambu is a command line tool
// Supports most C/{cpp} constructs
// Bambu has three phases. frontend, middleend and backend
// Frontend: Uses Clang or gcc
// Uses a compiler plugin for both extracting the call graph and control flow information
// Builds its own static single assignment IR
// This decouples the compiler front end from the rest of the HLS process.
// Vivado HLS has a frontend based on Clang
// Middle end:
// Bambu rebuilds the call graph and control data flow graph and adds its own data structures.
// Applies a set of analyses and transformations.
// Including common software compilation optimizations
// Including target-specific transformations. Such as replacing multiplication and divisions with constants with shift and add operations.
// Can exploit custom-sized operators
// TODO: Explore if Bambu can use the rust crate for more integer sizes like u21
// Bambu performs bitwidth and range analysis to minimize bit width
// Backend: Bambu performs the actual architectural synthesis here
// The synthesis process acts on every function individually
// Every function has at least two parts: control logic and datapath
// Control logic is an FSM
// Control logic handles the routing of data values and temporal execution of ops
// Bambu steps:
// * Function allocation
// Bambu has a technology library for standard system libraries such as libm or libs
// This step associates High-level functions with hardware resources
// Bambu supports sharing functions across module boundaries
// * Memory allocation
// Defines memories to store variables.
// Defines how dynamic memory is implemented
// Memories in Bambu can be classified as read-only, local, with aligned or unaligned memory access
// Bambu supports accessing protocol-based memories
// * Resource allocation
// Maps operations (not mapped onto functions) onto resource units
// Resource units are available in the Bambu's resource library
// Floating point operations are supported by generating soft floating point cores
// Rich resource library with multiple implementations for the same operation
// Resource library annotated with latency and resource occupation.
// * Scheduling
// Bambu uses List scheduling
// Every operation has a priority
// An operation is ready when its dependencies have been satisfied
// Ready operations can be scheduled if the resources are available
// Multiple competing for a resource: higher priority
// Also has a speculative scheduling algo
// * binding
// Pretty much standard
// Bambu considers how profitable it is for two operations to share the same resource
// Resources that occupy a big area are more likely to be shared
// * netlist generation
// Translates the architecture in an RTL description
// In Verilog or VHDL
//
// Research topics for Bambu: "They range from parallelized hardware accelerator design, dynamic scheduling, verification, and debugging, design exploration of the compilation flow, machine learning accelerator design, IR development, and integration with logic synthesis tools", MLIR
// MLIR dialects that can be translated to LLVM IR
* [[[Fer21]]]
+Fabrizio Ferrandi, Vito Giovanni Castellana, Serena Curzel, Pietro Fezzardi, Michele Fiorito, Marco Lattuada, Marco Minutoli, Christian Pilato, Antonino Tumeo+ +
_Invited: Bambu: an Open-Source Research Framework for the High-Level Synthesis of Complex Applications_ +
ACM/IEEE Design Automation Conference +
link:pass:[https://doi.org/10.1109/DAC18074.2021.9586110][10.1109/DAC18074.2021.9586110^]
link:pass:[https://re.public.polimi.it/retrieve/668507/dac21_bambu.pdf][üìÅ^]

// * [[[Rot10]]]
// +Nadav Rotem,+
// _C-to-Verilog. com: High-Level Synthesis Using LLVM_,
// University of Haifa,
// 2010.
// link:pass:[https://llvm.org/devmtg/2010-11/Rotem-CToVerilog.pdf][üîó^]

// * [[[Sch20]]]
// +Fabian Schuiki, Andreas Kurth, Tobias Grosser, and Luca Benini+,
// _LLHD: a multi-level intermediate representation for hardware description languages_,
// In Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2020), 258-271,
// 2020.
// link:pass:[https://doi.org/10.1145/3385412.3386024][üîó^]

// Multiple HLS tools use LLVM
// C/Cpp are the most popular languages for HLS
// NOTE: I focused on FPGA descriptions
// Clock frequency scaling in CPU stalled around 2005
// A alternative approach for high-throughput and energy-efficient processing is to use specific accelerators
// Specialized accelerators are hard to design and program
// RTL requires advanced hardware expertise
// RTL specifies cycle-by-cycle behavior explicitly
// RTL is a low-level abstraction
// RTL leads to longer development times
// FPGAs with HLS can reduce that.
// FPGAs are configurable integrated circuits
// Most FPGAs are reconfigurable
// FPGA vendors provide toolchains to synthesize HTL to bitstream
// bitstream gets programmed to the FPGA
// HLS tools start from an HLL and automatically produce a circuit specification in RTL
// HLS offers to enable software engineers to benefit from the performance and energy efficiency of hardware without having hardware expertise
// HLS tools enable hardware engineers to design systems faster
// HLS tools enable hardware engineers to explore the design space rapidly
// Microsoft uses FPGAs to accelerate Bing search
//
// 
* [[[Nan16]]]
+Razvan Nane, Vlad-Mihai Sima, Christian Pilato, Jongsok Choi, Blair Fort, Andrew Canis, Yu Ting Chen, Hsuan Hsiao, Stephen Brown, Fabrizio Ferrandi, Jason Anderson, Koen Bertels+ +
_A Survey and Evaluation of FPGA High-Level Synthesis Tools_ +
IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems +
link:pass:[https://doi.org/10.1109/tcad.2015.2513673][10.1109/tcad.2015.2513673^]
link:pass:[https://sci-hub.st/10.1109/tcad.2015.2513673][üìÅ^]

// * [[[Nor18]]]
// +D. H. Noronha, B. Salehpour and S. J. E. Wilton+,
// _LeFlow: Enabling Flexible FPGA High-Level Synthesis of Tensorflow Deep Neural Networks_,
// Fifth International Workshop on FPGAs for Software Programmers, 1-8,
// 2018.
// link:pass:[https://ieeexplore.ieee.org/abstract/document/8470462][üîó^]

// SystemVerilog is the de facto standard for RTL design
* [[[Soz22]]]
+Emanuele Del Sozzo, Davide Conficconi, Alberto Zeni, Mirko Salaris, Donatella Sciuto, Marco D. Santambrogio+ +
_Pushing the level of abstraction of digital system design: A survey on how to program FPGAs_ +
ACM Computing Surveys +
link:pass:[https://doi.org/10.1145/3532989][10.1145/3532989^]
link:pass:[https://re.public.polimi.it/retrieve/e3b8d0bb-125b-4457-9780-250f72ef7a02/Survey_FPGA_CSUR.pdf][üìÅ^]

// * [[[XLS]]]
// _XLS project page_
// link:pass:[https://google.github.io/xls/][üîó^]

// * [[[DSLX]]]
// _DSLX Reference_
// link:pass:[https://google.github.io/xls/dslx_reference/][üîó^]




// * [[[Zen12]]]
// _Identifying Barriers to Adoption for Rust through Online Discourse_
// link:pass:[https://arxiv.org/pdf/1901.01001.pdf][üîó^]

// Rust has an ecosystem that greatly simplifies any software project
// Rust is great
// Rust has been the "most loved" language since 2016
// Rust is meant to supersede C/{cpp}
// Rust's focus is on safety and performance
// For any need, you may have libraries exist 
// Dependencies can be installed using the official cargo tool
// Rust is the first industry-supported computer programming language to overcome the longstanding trade-off between the control over resource management provided by lower-level languages for systems programming, and the safety guarantees of higher-level languages
// Rust enables many common systems programming pitfalls to be detected at compile-time
// Rust surpasses all other common memory-safe languages in terms of performance
// Rust has data-race prevention
// Considering performance Rust is one of the best languages
// Considering safety, Rust is the best language
// Rust offers many modern features that the more established systems-programming languages tend to lack.
// Cargo is the package manager for Rust
// Cargo is the build system for Rust
// Cargo facilitates downloading and building dependencies
// Cargo facilitates unit testing and integration testing
// Cargo facilitates benchmarking
// Cargo facilitates build management with different profiles
// Cargo facilitates documentation generation from comments
// Rustfmt facilitates code formatting
// Dependency management is handled with a configuration file
// Dependencies are automatically installed during compilation
// Dependencies can be easily found on the official community crates registry
// Cargo allows viewing unified documentation for all dependencies
// Unit tests are written in the same file as the code they test
// Benchmarking is done in a similar fashion to unit testing
// The tooling alone makes Rust a much better development experience than most systems languages
// The tooling is most likely a considerable contributor to its rise.
// Rust is approaching the status of a mainstream language in health informatics applications
// The criticisms of Rust tend to originate from its lack of maturity
// C and {cpp} are well-adopted and much more established in the industry than Rust
// lack of demand for Rust developers in the market
* [[[Bug22]]]
+William Bugden, Ayman Alahmar+ +
_Rust: The Programming Language for Safety and Performance_ +
arXiv preprint +
link:pass:[https://doi.org/10.48550/arXiv.2206.05503][10.48550/arXiv.2206.05503^]
link:pass:[https://arxiv.org/pdf/2206.05503.pdf][üìÅ^]

// Rust can be used for GPU programming
* [[[Byc22]]]
+Andrey Bychkov, Vsevolod Nikolskiy+ +
_Rust Language for GPU Programming_ +
Russian Supercomputing Days, Revised Selected Papers +
link:pass:[https://doi.org/10.1007/978-3-031-22941-1_38][10.1007/978-3-031-22941-1_38^]
link:pass:[https://link.springer.com/content/pdf/10.1007/978-3-031-22941-1_38.pdf][üìÅ^]

// Rust can be used for web programming
* [[[Kyr22]]]
+Kyriakos-Ioannis D. Kyriakou, Nikolaos D. Tselikas+ +
_Complementing JavaScript in High-Performance Node.js and Web Applications with Rust and WebAssembly._ +
Electronics +
link:pass:[https://doi.org/10.3390/electronics11193217][10.3390/electronics11193217^]
link:pass:[https://mdpi-res.com/d_attachment/electronics/electronics-11-03217/article_deploy/electronics-11-03217-v2.pdf?version=1665474262][üìÅ^]

// Probably one of the greatest features of the language is the package manager, called cargo.
// Rust is a high-level language
// Rust is very efficient in terms of performance
// Rust is based on the principle of zero-cost abstractions
// Rust provides a memory safety mechanism without using a garbage collector called the borrow checker
// Rust is a strongly typed language
// Rust provides an out-of-the-box package manager used for importing dependencies, building, and distributing a project.
// If a variable is declared in a specific context, it will be freed when the context is over.
// The ownership of a variable can be passed to another context
// More basic description of Rust ownership stuff will skip that for now
// Development in {cpp} on a production level requires the use of additional tools such as CMake, Make, etc. This adds a layer of complexity.
// Rust has mandatory tooling for building, distributing, and depending on a project
// In Rust, only a manifest file is needed to configure the project for any scenario possible
// Rust can be compiled into web assembly
// Rust is more energy efficient than any other language except C for IoT applications
// Rust is faster than any other language except C for IoT applications
// Rust can easily integrate with C or {cpp} code
// Rust solves the problem of memory safety without using a garbage collector
// Microsoft states that 70% of security flaws discovered in their systems are related to memory safety
* [[[Cos19]]]
+Cosmin Cartas+ +
_Rust - The Programming Language for Every Industry_ +
Economic Informatics Journal +
link:pass:[https://doi.org/10.12948/ei2019.01.05][10.12948/ei2019.01.05^]
link:pass:[https://arxiv.org/pdf/2206.05503.pdf][üìÅ^]

// state-of-art bottom-up logic programming within the Rust ecosystem
* [[[Sah22]]]
+Arash Sahebolamri, Thomas Gilray, Kristopher Micinski+ +
_Seamless Deductive Inference via Macros_ +
ACM SIGPLAN International Conference on Compiler Construction +
link:pass:[https://doi.org/10.1145/3497776.3517779][10.1145/3497776.3517779^]
link:pass:[https://thomas.gilray.org/pdf/seamless-deductive.pdf][üìÅ^]

// Productivity in HLS is better than HDL
// HLS offers easier design and testing
// HDL implementation is better than HLS
* [[[Mil20]]]
+Roberto Mill√≥n, Emmanuel Frati, Enzo Rucci+ +
_A Comparative Study between HLS and HDL on SoC for Image Processing Applications_ +
Revista elektron +
link:pass:[https://doi.org/10.37537/rev.elektron.4.2.117.2020][10.37537/rev.elektron.4.2.117.2020^]
link:pass:[https://arxiv.org/pdf/2012.08320.pdf][üìÅ^]

// Describing the traditional HDL design flow (in 1996)
// TODO: Find a newer source
* [[[Smi96]]]
+Douglas J. Smith+ +
_VHDL & Verilog compared & contrasted‚Äîplus modeled example written in VHDL, Verilog and C._ +
Annual Design Automation Conference +
link:pass:[https://doi.org/10.1145/240518.240664][10.1145/240518.240664^]
link:pass:[https://dl.acm.org/doi/pdf/10.1145/240518.240664][üìÅ^]

// 
* [[[Fla20]]]
+Peter Flake, Phil Moorby, Steve Golson, Arturo Salz, Simon J. Davidmann+ +
_Verilog HDL and its ancestors and descendants._ +
Proceedings of the ACM on Programming Languages +
link:pass:[https://doi.org/10.1145/3386337][10.1145/3386337^]
link:pass:[https://dl.acm.org/doi/pdf/10.1145/3386337][üìÅ^]
// link:pass:[https://www.researchgate.net/profile/Arturo-Salz-2/publication/342137214_Verilog_HDL_and_its_ancestors_and_descendants/links/613fc7b45d9d0e131b427dbb/Verilog-HDL-and-its-ancestors-and-descendants.pdf][üîó^]

// * [[[intel-hls]]]
// _Intel¬Æ High Level Synthesis Compiler_
// https://www.intel.de/content/www/de/de/software/programmable/quartus-prime/hls-compiler.html

// * [[[hdl-to-adl]]]
// _From Hardware Description Languages to Accelerator Design Languages_
// https://www.sigarch.org/hdl-to-adl/


// Survey literature from 2010 to 2016
// Probably the best comparison of HLS and RTL
// Also, the newest
// Shows that the quality of results of RTL is better than that of HLS
// Shows that development time with HLS is a third of that of the RTL flow
// Shows that the productivity of a designer is over four times higher with HLS than with RTL
// Vivado HLS is the most common HLS tool. At least it is used significantly more than any other HLS tool in papers.
// Xilinx is the leading FPGA vendor
// FPGAs are made of configurable logic blocks (CLB, different vendors, different names).
// The CLBs are connected with programmable interconnects.
// The CLBs consist of a few logic cells, logic elements, or adaptive logic modules (ALM) (LC, LE, and ALM are the same. Different vendors use different names).
// Logic cells are made of a combination of programmable look-up tables (LUTs) and flip-flops (FFs).
// FPGAs can also have other resources, but these are vendor specific. Most commonly, DSP blocks and BRAM blocks.
// There are four performance metrics that are commonly used to compare HLS and RTL: performance, execution time, latency, maximum frequency
// For projects bigger than 250 lines of code HLS also needs fewer lines of code than RTL
// Reduction in development time for HLS seems independent of project size.
// On average, HLS uses 41% more basic FPGA resources than RTL
// The usage of advanced FPGA resources of HLS is similar to RTL
// C-based languages are the most common, then OpenCL-based, then high-level language based.
// CUDA/OpenCL-based HLS is especially resource-consuming and has the worst performance
// The performance of HLS designs is similar to the performance of RTL designs.
// The only example in academia where the development time of HLS was more than RTL was when the developer had to learn the HLS tool in the process.
// Only looks at small to medium designs, 50-500 lines of code
// It is easier to adopt HLS than RTL for people who have experience in software design
// HLS allows for efficient behavioral verification
// The HLS output must still be verified for non-behavioral aspects. This traditional verification is difficult because there is no direct relationship to the source code.
// HLS halves verification time in many cases
// HLS is a particularly good choice when the time to market is a dominant issue, and there is no compelling need to gain the ultimate performance or smallest resource usage for the product
// There is no standard example to compare HLS and RTL
* [[[Lah19]]]
+Sakari Lahti, Panu Sj√∂vall, Jarno Vanne, Timo D. H√§m√§l√§inen+ +
_Are We There Yet? A Study on the State of High-Level Synthesis_ +
IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems +
link:pass:[https://doi.org/10.1109/TCAD.2018.2834439][10.1109/TCAD.2018.2834439^]
link:pass:[https://sci-hub.st/10.1109/tcad.2018.2834439][üìÅ^]


// Studied Rust‚Äôs ownership discipline in the presence of unsafe code.
// Shows that various important Rust libraries with unsafe implementations, many of them involving interior mutability, are safely encapsulated by their type
// NOTE: Did only read the abstract and conclusion
* [[[Jun17]]]
+Ralf Jung, Jacques-Henri Jourdan, Robbert Krebbers, Derek Dreyer+ +
_RustBelt: Securing the Foundations of the Rust Programming Language_ +
Proceedings of the ACM on Programming Languages +
link:pass:[https://doi.org/10.1145/3158154][10.1145/3158154^]
link:pass:[https://dl.acm.org/doi/pdf/10.1145/3158154][üìÅ^]

// Cpp uses RAII
// "In particular, a programmer can choose to write a low-level-C style and/or violate every rule of good programming. That is not my topic here."
* [[[Str12]]]
+Bjarne Stroustrup+ +
_Foundations of {cpp}_ +
Programming Languages and Systems +
link:pass:[https://doi.org/10.1007/978-3-642-28869-2_1][10.1007/978-3-642-28869-2_1^]
link:pass:[https://link.springer.com/content/pdf/10.1007/978-3-642-28869-2_1.pdf][üìÅ^]



// LLVM is a compiler framework
// Defines a low-level code representation in a single static assignment (SSA) form
// LLVM IR
// Describes a program using an abstract RISC-like instruction set with higher-level information
// LLVM IR contains type information
// LLVM IR contains explicit control flow graphs
// LLVM IR contains explicit dataflow representation (using SSA)
// Has a low-level, language-independent type system
// Has instructions for performing type conversions and low-level address arithmetic while preserving type information.
// Low-level exception handling instructions
// LLVM is not intended to be a universal compiler IR
// does not represent high-level language features directly
// LLVM has no notion of high-level constructs such as classes, inheritance, or exception-handling semantics
// LLVM does not specify a runtime system or particular object model
// "Type information captured by LLVM is enough to safely perform a number of aggressive transformations that would traditionally be attempted only on type-safe languages in source-level compilers."
// NOTE: I skipped section 2
// "The goal of the LLVM compiler framework is to enable sophisticated transformations at link-time, install-time, runtime, and idle-time, by operating on the LLVM representation of a program at all stages."
// Static compiler front-ends emit code in the LLVM representation
// combined by the LLVM linker
// Linker performs a variety of link time optimizations
// The resulting code is then translated to native code for a given target.
// Language-specific optimizations must be performed in the frontend
// External static LLVM compilers are known as front-ends
// Frontends translate source language programs into LLVM IR
// Can perform aggressive interprocedural optimizations across the entire program
// Some of the interprocedural optimizations are:  inlining, dead global elimination, dead argument elimination, dead type elimination, constant propagation, array bounds check elimination, simple structure field reordering, and Automatic Pool Allocation
// Uses code generator backends to translate LLVM IR into native code for a given target
* [[[Lat04]]]
+Chris Lattner, Vikram Adve+ +
_LLVM: a compilation framework for lifelong program analysis & transformation_ +
International Symposium on Code Generation and Optimization +
link:pass:[https://doi.org/10.1109/CGO.2004.1281665][10.1109/CGO.2004.1281665^]
link:pass:[https://llvm.org/pubs/2004-01-30-CGO-LLVM.pdf][üìÅ^]
// Shows that HLS is twice as fast as HDL 
// M. Pelcat, C. Bourrasset, L. Maggiani and F. Berry, "Design productivity of a high-level synthesis compiler versus HDL," 2016 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS), Agios Konstantinos, Greece, 2016, pp. 140-147, doi: 10.1109/SAMOS.2016.7818341.
// https://ieeexplore.ieee.org/abstract/document/7818341

// FPGA inception 30 years ago
// FPGAs bring faster design cycles than custom chips
// FPGAs lower dev cost than custom chips
// low-level hardware reconfigurability
// FPGA architecture offers many design choices
// FPGAs consist of different types of programmable blocks
// "FPGAs are reconfigurable computer chips that can be programmed to implement any digital circuit."
// prefabricated routing tracks with programmable switches
// Functionality of all FPGA blocks is controlled by SRAM cells
// Milloions of SRAM cells
// HDL is converted to bitstream
// Bitstream is used to program all configuration SRAM cells
// Lower NRE cost than ASICs
// Shorter time to market than ASICs
// off-the-shelf FPGA can be used to implement a design in a matter of weeks
// Skipping physical design, layout, fabrication, and verification
// Allow continuous hardware upgrades by loading new bitstreams in the field
// Considered a compelling solution for small and medium-sized designs 
// Exact hardware for every application
// Exact datapath width, pipeline stages, and parallel units as required
// Can achieve higher efficiency than CPU or GPU
// Can implement instruction-free streaming hardware
// Can implement a custom instruction set
// Adopted in many domains.
// "adoption of FPGAs in many application domains including wireless communications, embedded signal processing, networking, ASIC prototyping, high-frequency trading, and many more."
// Deployed on a large scale in data centers, packet processing, machine learning
// Lower efficiency than ASICs
// FPGA, on average 35 times larger than ASIC implementation
// FPGA, on average four times slower than ASIC implementation
// For designs that utilize other FPGA blocks, the gap is smaller, still nine times large
// FPGA architects seek to reduce the gap while maintaining programmability
// Early FPGAs were simple arrays of logic blocks
// Modern FPGAs are complex heterogeneous architectures that have more block types
// Modern FPGA have blocks like BRAM, DSP, processors, external interfaces
// FPGA architectures are evaluated based on the efficiency of implementing a wide variety of designs
// There are academic test suites for evaluating FPGA architectures
// VTR is a CAD system to layout designs on FPGAs
// CAD system applies a series of complex optimizations 
// CAD system converts RTL design to netlist.
// CAD system maps netlist to FPGA blocks
// CAD system places blocks on FPGA and routes the connections between them
// CAD system outputs bitstream implementation
// Total area is a key metric
// "Total area is the sum of the areas of the FPGA blocks used by the application, along with the programmable routing included with them."
// Timing analyzer finds the critical path through blocks and routing
// Critical path limits maximum clock frequency
// Power consumption is estimated based on resources used and signal toggle rate
// _hardened_ blocks are blocks that are implemented as ASICs
// What functionality to harden is a design choice
// What area of the FPGA to use for hardened blocks is a design choice
// Hardened blocks can still have some level of configurability
// How flexible the hardened blocks are is a design choice
// Hardened blocks are faster, smaller and more power efficient than programmable blocks
// Tradeoff between flexibility and efficiency
// Unused hardened blocks are wasted silicon
// Problems with slow routing to hardened blocks, if they are far away
// PAL first reconfigurable computing devices
// PAL does not scale well; area increases quadratically with IO size
// CPLD includes multiple PALs and programmable routing in a package
// 1984 Xilinx pioneers first LUT-based FPGA
// SRAM-based LUTs with interconnects between them
// Scales well
// Much higher area efficiency than and/or based designs
// LUTs form the fundamental logic element in all commercial FPGAs
// Alternative designs perform worse than LUTs
// K-LUT implements a K-input LUT
// K-LUT stores the truth table in SRAM cells,
// K input signals are used as multiplexers to select line
// truth table contains 2^K values
// A basic logic element (BLE) is a K-LUT with an output register
// A BLE can implement DFF or a K-LUT
// A BLE has K inputs and two outputs, one for routing and one for feedback inside the LE
// Logic blocks are composed of multiple (N) BLEs
// Logic blocks have a local interconnect
// The local interconnect connects the inputs of the LB and the feedback outputs of the BLEs to the inputs of the BLEs.
// The local interconnect is often arranged as a local full or partial crossbar.
// See Figure 4 in the paper.
// Over time, K and N have increased.
// More K means more functionality in a single LUT
// More K leads to less logic in the critical path
// More N means less demand for fast inter-LB routing
// The area of the LUT increases exponentially with K as more SRAM cells are needed (2^K)
// More K linearly degrades the speed of the LUT
// If the local interconnect is a crossbar, its size increases quadratically with N
// If the local interconnect is a crossbar, its size decreases linearly with N
// Empirically, the best size for K is 4-6, and for N, it is 3-10
// First LUT-based FPGA from Xilinx: N = 2, K = 3
// Around 2000: 4-LUTs common
// Study: 4-LUTs vs 6-LUTS: 6-LUTS:14% more perf, 17% bigger
// Fracturable LUTs can be broken down into smaller LUTs, but limitations like shared inputs
// FPGA architectures from Xilinx and Altera converge to relatively large LBs with 8 and 10 N
// Future designs even bigger LBs
// inter-LB wire delay scales poorly with a process shrink
// Larger LB sizes can lead to faster CAD tool runtimes
// Modern FPGAs have more than 1 FFs per BLE
// Even though there are optimization, the core ideas stayed similar
// 22% of logic elements in FPGAs are implementing arithmetic
// These operations can be implemented with LUTs but are inefficient
// A ripple carry adder requires 2 * the number of bits LUTs
// This leads to high logic utilization and long critical paths
// All modern FPGAs include hardened arithmetic circuitry in their logic blocks
// How the arithmetic is accelerated is a design choice
// It can be a dedicated adder between two LUTs
// It can be just a fast path for the carry bit
// At least 3x faster than LUT-based implementations
// NOTE: there is more detail on the different types of arithmetic optimizations in the paper
// Recently, deep learning has become a key workload
// Deep learning has multiply-accumulate operations at its core, which could benefit from hardened, bigger hardened arithmetic
// Programmable routing is over 50% of the area of an FPGA
// Programmable routing accounts for over half the critical path delay
// High multiplier density in signal processing and communication applications
// Main design philosophy of the DSP block is to minimize the number of soft logic used to implement common DSP algorithms
// FPGA CAD tools will automatically map multiplication to DSP blocks
// Bigger FPGA designs always require a memory buffer
// Making soft memory out of LUTs is over 100x less dense than SRAM cells
// Modern FPGAs are about 25% BRAM
* [[[Bot21]]]
+Andrew Boutros, Betz Vaughn+ +
_FPGA architecture: Principles and progression_ +
IEEE Circuits and Systems Magazine +
link:pass:[https://doi.org/10.1109/MCAS.2021.3071607][10.1109/MCAS.2021.3071607^]
link:pass:[https://www.eecg.utoronto.ca/~vaughn/papers/casm2021_arch_survey.pdf][üìÅ^]

// TODO: This is an application note; how to cite it?
// TODO: Especially Cri in the link is wrong
// TODO: Source for one definition. Necessary?
// A critical path is a path in the design which must meet certain critical timing requirements in order for the system to function properly
* [[[Mic95]]]
+Microprocessors and Microsystems+ +
_Critical path analysis for field-programmable gate arrays_ +
Microprocessors and Microsystems +
link:pass:[https://doi.org/10.1016/0141-9331(95)90010-1][10.1016/0141-9331(95)90010-1^]
link:pass:[https://sci-hub.st/10.1016/0141-9331(95)90010-1][üìÅ^]

// Compares RTL/HDL to assembly
// High-level languages improved productivity
// HDL has enabled the wide adoption of simulation tools
// First HLS tools 1990s
// In the 2000s: shift to electronic system level (ESL) paradigm that facilitates exploration synthesis and verification of complex SoCs
// Intro of first languages with a system-level abstraction like SystemC or SystemVerilog
// 2000s transaction-level modeling
// ESL paradigm shift caused by rising system complexities
// HLS reduced time for creating hardware
// HLS reduced time for verification
// HLS enables the reuse of the same specification for different targets (ASICs, FPGAs, different ASICS, and FPGAs)
// functional specification = untimed high level description
// NOTE: contains more info about HLS design flow
// HLS tools transform an untimed specification into a fully timed implementation
// HLS tools generate custom architecture to efficiently implement the specification
// HLS tools generate an RTL implementation
// DIAGRAM: High-level synthesis design steps
// Generated architecture (usually) consists of a datapath and a controller.
// Generated architecture also has memory banks and communications interfaces.
// HLS tools usually perform seven tasks:
// 1. Compiling the specification
// 2. Allocating/Creating hardware resources
// 3. Scheduling operations to clock cycles
// 4. Binding operations to functional units
// 5. Binding variables to storage elements
// 6. Binding transfers to connection units
// 7. Generating the RTL architecture
// Steps 2-6 are called interdependent
// Compiling transforms the specification into a formal description
// Compiling performs optimizations
// Formal model classically exhibits data and control dependencies.
// Data flow graph: Every operation is a node, and the edges are values (input, temporary, and output)
// A pure data flow graph (DFG) models data flow only
// In some cases, a pure DFG can be created. Can be done by completely unrolling loops and multiplexing conditional assignments.
// Pure DFG is big and impractical
// Cannot support unbounded iteration and nonstatic control flow (like goto)
// control and data flow graph (CDFG) models data and control flow
// CDFG nodes are called basic blocks and are a straight sequence of statements
// CDFG edges can be conditional and represent if or switch constructs.
// CDFGs are more expressive because they can represent loops with unbounded iteration (those that cannot be unrolled)
// Allocation defines the types and number of resources that are needed to satisfy the design constraints
// Resources are functional units, storage elements, and communication interfaces
// HLS tools have an RTL component library with basic resources.
// Scheduling determines which operations run in which clock cycle.
// All operations must be scheduled into cycles
// If there are no data dependencies between operations, they can be scheduled in parallel
// Every variable that carries values over multiple cycles must be bound to a storage element
// Variables with nonoverlapping lifetimes can be bound to the same storage element
// Every operation must be bound to a functional unit that can perform the operation
// Every connection between functional units and storage elements must be bound to a connection unit
// After allocation, scheduling, and binding, the RTL architecture can be generated and output
// The architecture classically includes a controller and a datapath
// Storage elements: registers, memories, etc.
// functional units: ALUs, multipliers, DSPs, and other custom functions, etc.
// connection units: buses, tristate drivers, multiplexers, etc.
// The datapath consists of the storage elements, functional units, and connection units
// All these components can be connected arbitrarily through buses
// They can also be pipelined
// The controller is a finite state machine (FSM)
// The controller orchestrates the datapath by setting values of control signals of the datapath
// The inputs of the controller can come from primary inputs or from the datapath
// The controller consists of three parts: the next state logic, a state register, and the output logic.
// The next state logic computes the next state of the FSM from the current state and the inputs.
// The state register contains the current state of the controller
// The output logic sets the control signals according to the current state
// The output logic also sets control outputs that can be used as inputs for the datapath
// The controller is usually built with hardwired logic but can be more complex with memories and such
// The controller is usually a custom processor if it is more complex.
// The state register is then called the program counter. This shows that it is just a processor.
// NOTE: Only read until "Several design-flows."
* [[[Cou09]]]
+Philippe Coussy, Daniel D. Gajski, Michael Meredith, Andres Takach+ +
_An Introduction to High-Level Synthesis_ +
IEEE Design & Test of Computers +
link:pass:[https://doi.org/10.1109/MDT.2009.69][10.1109/MDT.2009.69^]
link:pass:[http://www.cs.columbia.edu/~cs6861/handouts/coussy-DT-09.pdf][üìÅ^]

// Harry Foster has newer studies but no publications assoc with them, only blog posts
// They say basically the same things
// System verilog is the most common HDL
* [[[Fos15]]]
+Harry D. Foster+ +
_Trends in Functional Verification: A 2014 Industry Study_ +
Annual Design Automation Conference +
link:pass:[https://doi.org/10.1145/2744769.2744921][10.1145/2744769.2744921^]
link:pass:[http://www.eecs.umich.edu/courses/eecs578/eecs578.f15/papers/fos15.pdf][üìÅ^]

// * [[[Ber09]]]
// +Guido Bertoni, Joan Daemen, Micha√´l Peeters, Gilles Van Assche+,
// _Keccak sponge function family main document._,
// Submission to NIST (Round 2) 3, no. 30 (2009): 320-337,
// 2009
// link:pass:[https://keccak.team/files/Keccak-submission-3.pdf][üìÅ^]



// Softcores are slower than ASICs
// There are soft cores that are specially designed for FPGAs
* [[[Bal07]]]
+James Ball+ +
_Designing soft-core processors for FPGAs_ +
Processor Design +
link:pass:[https://doi.org/10.1007/978-1-4020-5530-0_11][10.1007/978-1-4020-5530-0_11^]
link:pass:[https://sci-hub.st/10.1007/978-1-4020-5530-0_11][üìÅ^]

// Opensource tools catch up with the vendor tooling
* [[[Bar23]]]
+Benjamin L.C. Barzen, Arya Reais-Parsi, Eddie Hung, Minwoo Kang, Alan Mishchenko, Jonathan W. Greene, John Wawrzynek+ +
_Narrowing the Synthesis Gap: Academic FPGA Synthesis is Catching Up With the Industry_ +
Design, Automation & Test in Europe Conference and Exhibition +
link:pass:[https://doi.org/10.23919/DATE56975.2023.10137310][10.23919/DATE56975.2023.10137310^]
link:pass:[http://people.eecs.berkeley.edu/~alanmi/publications/2023/date23_gap.pdf][üìÅ^]

// Rust compiler has multiple intermediate representations (IRs)
// * MIR (Mid-level IR)
// * HIR (High-level IR)
// * THIR (Typed HIR)
// * LLVM IR
// Typechecking happens on HIR
// Optimization happens on MIR
// MIR is a typed SSA
// Borrowchecking happens at the MIR level
// Optimizations also happen in LLVM
// LLVM is used as the backend
// LLVM can generate machine code for many architectures
// LLVM is a collection of modular and reusable compiler and toolchain technologies
// LLVM contains a pluggable compiler backend used by rustc and Clang
// Clang is a C compiler
// LLVM takes LLVM IR
// Rust compiler uses LLVM because
// * They don't have to write their own backend. Reduces implementation and maintenance effort.
// * Benefit from the large suite of advanced optimizations that LLVM provides
// * Rust can be compiled into any of the platforms that LLVM supports.
// * Community benfits. Things like specter and meltdown only need to be fixed in LLVM, and many compilers benefit from that
// rustc groups LLVM IR into "modules" known as codegen units
// Rustc can use LLVM to codegen multiple of these modules in parallel utilizing multiple CPU cores
// The resulting object files are then linked together by the linker
* [[[Rus18]]]
+The Rust Project Developers+ +
_Rust Compiler Development Guide (rustc-dev-guide)_ +
[Online; accessed 5.7.23] +
link:pass:[https://github.com/rust-lang/rustc-dev-guide][github.com/rust-lang/rustc-dev-guide^]
link:pass:[https://rustc-dev-guide.rust-lang.org/backend/codegen.html][üìÅ^]

// Rust is the most loved language of 2016
* [[[Sta16]]]
+Stack Overflow+ +
_Stack Overflow Developer Survey 2016_ +
[Online; accessed 5.7.23] +
link:pass:[https://insights.stackoverflow.com/survey/2016/][insights.stackoverflow.com/survey/2016^]

// Rust is the most loved language of 2020
* [[[Sta20]]]
+Stack Overflow+ +
_Stack Overflow Developer Survey 2020_ +
[Online; accessed 5.7.23] +
link:pass:[https://insights.stackoverflow.com/survey/2020/][insights.stackoverflow.com/survey/2020^]

// Rust is the most loved language of 2023
* [[[Sta23]]]
+Stack Overflow+ +
_Stack Overflow Developer Survey 2023_ +
[Online; accessed 5.7.23] +
link:pass:[https://survey.stackoverflow.co/2023/][survey.stackoverflow.co/2023^]

* [[[Smi21]]]
+Smiths Digital Forge, Samit Basu+ +
_A framework for writing FPGA firmware using the Rust Programming Language_ +
[Online; accessed 5.7.23] +
link:pass:[https://github.com/samitbasu/rust-hdl][github.com/samitbasu/rust-hdl^]

* [[[Rus23]]]
+RustCrypto Developers+ +
_Pure Rust implementation of the latexmath:[\keccak] sponge function, including the latexmath:[\keccakfraw] and latexmath:[\keccakpraw] variants_ +
[Online; accessed 5.7.23] +
link:pass:[https://crates.io/crates/keccak][crates.io/crates/keccak^]

* [[[Kla23]]]
+Steve Klabnik, Carol Nichols+ +
_The Rust programming language_ +
[Online; accessed 5.7.23] +
link:pass:[https://doc.rust-lang.org/stable/book/][doc.rust-lang.org/stable/book^]

== Appendix



.Example of a generated RustHDL struct
[source#rust-hls-synthesized-listing.linenums.hundred_max,rust]
----
/// This file was generated by rust_hls. Please do not edit it manually.
/// rust_hls hash: "fc1b10f200f5632694995e666ba00202"

extern crate verilated;
use ::rust_hdl::prelude::*;

#[allow(dead_code, unused)]
mod minmax_verilated {
    /// Bindings to the C++ library generated by Verilator go here
}

#[derive(::std::default::Default)]
pub struct Minmax {
    pub clk: Signal<
        In,
        Clock,
    >,
    pub reset: Signal<In, bool>,
    pub start_port: Signal<In, bool>,
    pub elements: Signal<In,Bits<32usize>>,
    pub num_elements: Signal<In,Bits<32usize>>,
    pub m_rdata_ram: Signal<In,Bits<32usize>>,
    pub m_data_rdy: Signal<In, bool>,
    pub done_port: Signal<Out, bool>,
    pub return_port: Signal<Out,Bits<64usize>,>,
    pub mout_oe_ram: Signal<Out, bool>,
    pub mout_we_ram: Signal<Out, bool>,
    pub mout_addr_ram: Signal<Out,Bits<32usize>>,
    pub mout_wdata_ram: Signal<Out,Bits<32usize>>,
    pub mout_data_ram_size: Signal<Out,Bits<6usize>>,
    verilated_module: Arc<Mutex<self::minmax_verilated::MinmaxVerilated>>,
}
unsafe impl Send for Minmax {}

#[automatically_derived]
impl Logic for Minmax {
    fn update(&mut self) {
        let mut verilated_module = match self.verilated_module.lock() {
            Ok(verilated_module) => verilated_module,
            Err(e) => panic!("Failed to aquire verilated_module lock: {}", e),
        };
        verilated_module.set_clk(if self.clk.val().clk { 1u8 } else { 0u8 });
        verilated_module.set_reset(if self.reset.val() { 1u8 } else { 0u8 });
        verilated_module.set_start_port(if self.start_port.val() { 1u8 } else { 0u8 });
        verilated_module.set_Pd61(self.elements.val().to_u32());
        verilated_module.set_Pd62(self.num_elements.val().to_u32());
        verilated_module.set_M_Rdata_ram(self.m_rdata_ram.val().to_u32());
        verilated_module.set_M_DataRdy(if self.m_data_rdy.val() { 1u8 } else { 0u8 });
        verilated_module.eval();
        self.done_port.next = verilated_module.done_port() != 0;
        self
            .return_port
            .next = to_bits::<
            64usize,
        >(verilated_module.return_port() & 18446744073709551615u64);
        self.mout_oe_ram.next = verilated_module.Mout_oe_ram() != 0;
        self.mout_we_ram.next = verilated_module.Mout_we_ram() != 0;
        self.mout_addr_ram.next = to_bits::<32usize,>(
          verilated_module.Mout_addr_ram() & 4294967295u32);
        self.mout_wdata_ram.next = to_bits::<32usize,>(
          verilated_module.Mout_Wdata_ram() & 4294967295u32);
        self.mout_data_ram_size.next = to_bits::<6usize,>(
          verilated_module.Mout_data_ram_size() & 63u8);
    }
    fn connect(&mut self) {
        self.done_port.connect();
        self.return_port.connect();
        self.mout_oe_ram.connect();
        self.mout_we_ram.connect();
        self.mout_addr_ram.connect();
        self.mout_wdata_ram.connect();
        self.mout_data_ram_size.connect();
    }
    fn hdl(&self) -> Verilog {
        Verilog::Wrapper(Wrapper {
            code: r#"minmax minmax_inst(
                      .clk(clk), .reset(reset), .start_port(start_port),
                      .done_port(done_port), .return_port(return_port),
                      .Pd61(elements), .Pd62(num_elements),
                      .M_Rdata_ram(m_rdata_ram), .M_DataRdy(m_data_rdy),
                      .Mout_oe_ram(mout_oe_ram), .Mout_we_ram(mout_we_ram),
                      .Mout_addr_ram(mout_addr_ram), .Mout_Wdata_ram(mout_wdata_ram),
                      .Mout_data_ram_size(mout_data_ram_size));"#
                .into(),
            cores: "verilog generated by bambu ...",
        })
    }
}
----


// Reference thesis:
// * https://webthesis.biblio.polito.it/7573/1/tesi.pdf
// * https://scholarworks.gvsu.edu/cgi/viewcontent.cgi?article=1754&context=theses

include::scripts/trailing-scripts.adoc[]


// Final checklist:
// * are all abbreviations defined?
// * are all abbreviations linked to Wikipedia (or somewhere else)?
// * are all references used?
// * are all references linked to the correct source?
// * are all TODOs processed?
// * are the product names consistent? (Bambu)
// * check for duplicate references
// * check for broken references
// * archive.org all links
// * Check for duplication of information
// * oxford comma
// * style code blocks